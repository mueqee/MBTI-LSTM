{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline. Naive Bayes + Bag-of-Words\n",
        "\n",
        "---\n",
        "\n",
        "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–∏—Ö–æ—Ç–æ–º–∏–π MBTI —Å –ø–æ–º–æ—â—å—é Bag-of-Words + Multinomial Naive Bayes.\n",
        "\n",
        "**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:**\n",
        "- Multinomial Naive Bayes –Ω–∞ Bag-of-Words n-–≥—Ä–∞–º–º–∞—Ö (1-2)\n",
        "- 4 –±–∏–Ω–∞—Ä–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –¥–∏—Ö–æ—Ç–æ–º–∏–π: I/E, N/S, T/F, J/P\n",
        "\n",
        "**–ú–µ—Ç—Ä–∏–∫–∏:** accuracy –∏ F1 –¥–ª—è –∫–∞–∂–¥–æ–π –¥–∏—Ö–æ—Ç–æ–º–∏–∏ + exact match\n",
        "\n",
        "---\n",
        "\n",
        "vers. 1.0.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. –ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫\n",
        "\n",
        "–ò–º–ø–æ—Ä—Ç pandas, numpy, sklearn, matplotlib, seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q scikit-learn pandas numpy matplotlib seaborn\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞, —á—Ç–æ–±—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä\n",
        "project_root = os.path.abspath('..')\n",
        "sys.path.append(project_root)\n",
        "\n",
        "from src.data.preprocessor import MBTIPostPreprocessor\n",
        "\n",
        "print(\"‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "\n",
        "* –§–∞–π–ª: `data/raw/mbti_dataset.csv`\n",
        "* –ö–æ–ª–æ–Ω–∫–∏: `type`, `posts`\n",
        "* –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤, –ø—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
        "DATA_PATH = '../data/raw/mbti_dataset.csv'\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(f\"üìä –†–∞–∑–º–µ—Ä: {df.shape}\")\n",
        "print(df.head(2))\n",
        "\n",
        "# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤\n",
        "plt.figure(figsize=(10,4))\n",
        "ax = df['type'].value_counts().plot(kind='bar', color='steelblue')\n",
        "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ MBTI —Ç–∏–ø–æ–≤')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n–ü—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞:\\n\", df['posts'].iloc[0][:300], '...')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\n",
        "\n",
        "–ò—Å–ø–æ–ª—å–∑—É–µ–º `MBTIPostPreprocessor` (—Ç–æ—Ç –∂–µ, —á—Ç–æ –≤ LSTM-–ø–∞–π–ø–ª–∞–π–Ω–µ): \n",
        "* lowercase, —É–¥–∞–ª–µ–Ω–∏–µ URL/—Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤, —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, –ª–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è.\n",
        "* –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞–∂–¥—ã–π –ø–æ—Å—Ç –≤ –æ—á–∏—â–µ–Ω–Ω—É—é —Å—Ç—Ä–æ–∫—É –¥–ª—è Bag-of-Words.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –ø–æ—Å—Ç–æ–≤ (~2-3 –º–∏–Ω –Ω–∞ CPU)\n",
        "preprocessor = MBTIPostPreprocessor(\n",
        "    lowercase=True,\n",
        "    remove_urls=True,\n",
        "    remove_special_chars=True,\n",
        "    remove_stopwords=True,\n",
        "    lemmatize=True\n",
        ")\n",
        "\n",
        "df['clean_text'] = df['posts'].apply(preprocessor.preprocess_to_string)\n",
        "print(df[['posts', 'clean_text']].head(1).iloc[0].to_string())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Bag-of-Words –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è\n",
        "\n",
        "* `CountVectorizer(ngram_range=(1,2), max_features=10_000, stop_words='english')`\n",
        "* –ü–æ–ª—É—á–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ `X`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(ngram_range=(1,2), max_features=10_000, stop_words='english')\n",
        "X = vectorizer.fit_transform(df['clean_text'])\n",
        "print(f\"–ú–∞—Ç—Ä–∏—Ü–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–∫ –∏ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –≤—ã–±–æ—Ä–∫–∏\n",
        "\n",
        "* –ö–∞–∂–¥–∞—è –¥–∏—Ö–æ—Ç–æ–º–∏—è ‚Äî –Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è –±–∏–Ω–∞—Ä–Ω–∞—è –∑–∞–¥–∞—á–∞.\n",
        "* –°–æ–∑–¥–∞—ë–º `y_dict` —Å 4 –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏.\n",
        "* –ò—Å–ø–æ–ª—å–∑—É–µ–º `train_test_split` (70/30) —Å `stratify` –ø–æ –ø–æ–ª–Ω–æ–π MBTI-—Å—Ç—Ä–æ–∫–µ, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–∞–ª–∞–Ω—Å.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∏—Ö–æ—Ç–æ–º–∏–π\n",
        "DICHOTOMIES = [(0, 'IE'), (1, 'NS'), (2, 'TF'), (3, 'JP')]\n",
        "\n",
        "y_dict = {}\n",
        "for idx, name in DICHOTOMIES:\n",
        "    y = np.where(df['type'].str.upper().str[idx] == name[1], 1, 0)\n",
        "    y_dict[name] = y\n",
        "\n",
        "# Train/Test split –∏–Ω–¥–µ–∫—Å–æ–≤ (–æ–±—â–∏–π stratifiy)\n",
        "train_idx, test_idx = train_test_split(\n",
        "    np.arange(len(df)), test_size=0.3, stratify=df['type'], random_state=42)\n",
        "\n",
        "X_train, X_test = X[train_idx], X[test_idx]\n",
        "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. –û–±—É—á–µ–Ω–∏–µ Multinomial Naive Bayes\n",
        "\n",
        "* –û–±—É—á–∞–µ–º 4 –º–æ–¥–µ–ª–∏ ‚Äî –ø–æ –æ–¥–Ω–æ–π –Ω–∞ –¥–∏—Ö–æ—Ç–æ–º–∏—é.\n",
        "* –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ `results`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = {}\n",
        "results = {}\n",
        "\n",
        "for _, name in DICHOTOMIES:\n",
        "    y_train = y_dict[name][train_idx]\n",
        "    y_test = y_dict[name][test_idx]\n",
        "\n",
        "    clf = MultinomialNB(alpha=1.0)\n",
        "    clf.fit(X_train, y_train)\n",
        "    models[name] = clf\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
        "\n",
        "    results[name] = {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1}\n",
        "    print(f\"{name}: Acc={acc:.3f} | F1={f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Exact-match accuracy –∏ —Å–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞\n",
        "\n",
        "* –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—Å–µ—Ö 4 –º–æ–¥–µ–ª–µ–π.\n",
        "* –°—á–∏—Ç–∞–µ–º –¥–æ–ª—é –ø—Ä–∏–º–µ—Ä–æ–≤, –≥–¥–µ —É–≥–∞–¥–∞–Ω—ã –≤—Å–µ –¥–∏—Ö–æ—Ç–æ–º–∏–∏ —Å—Ä–∞–∑—É.\n",
        "* –§–æ—Ä–º–∏—Ä—É–µ–º DataFrame `results_df`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exact-match\n",
        "pred_matrix = []\n",
        "for _, name in DICHOTOMIES:\n",
        "    y_pred = models[name].predict(X_test)\n",
        "    pred_matrix.append(y_pred)\n",
        "\n",
        "y_pred_all = np.vstack(pred_matrix).T  # shape (n_samples, 4)\n",
        "\n",
        "y_test_all = np.vstack([y_dict[name][test_idx] for _, name in DICHOTOMIES]).T\n",
        "\n",
        "exact_match = (y_pred_all == y_test_all).all(axis=1).mean()\n",
        "print(f\"\\nExact-match accuracy (–ø–æ–ª–Ω—ã–π MBTI —Ç–∏–ø): {exact_match:.3f}\")\n",
        "\n",
        "# –¢–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫\n",
        "\n",
        "Bar-plot accuracy –∏ F1 –ø–æ –¥–∏—Ö–æ—Ç–æ–º–∏—è–º + —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å exact-match.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bar plot\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
        "\n",
        "results_df['acc'].plot(kind='bar', ax=ax[0], color='skyblue')\n",
        "ax[0].set_title('Accuracy –ø–æ –¥–∏—Ö–æ—Ç–æ–º–∏—è–º')\n",
        "ax[0].set_ylim(0,1)\n",
        "\n",
        "results_df['f1'].plot(kind='bar', ax=ax[1], color='salmon')\n",
        "ax[1].set_title('F1-score –ø–æ –¥–∏—Ö–æ—Ç–æ–º–∏—è–º')\n",
        "ax[1].set_ylim(0,1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Exact-match accuracy: {exact_match:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. –í—ã–≤–æ–¥—ã\n",
        "\n",
        "* Naive Bayes –¥–∞—ë—Ç –±–∞–∑–æ–≤—É—é —Ç–æ—á–Ω–æ—Å—Ç—å `~0.60` –Ω–∞ –ª—É—á—à–∏—Ö –¥–∏—Ö–æ—Ç–æ–º–∏—è—Ö.\n",
        "* Exact-match –Ω–∏–∂–µ (–æ–±—ã—á–Ω–æ ~0.25-0.30).\n",
        "* –ë–∏LSTM –∏–∑ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –Ω–æ—É—Ç–±—É–∫–∞ –æ–∂–∏–¥–∞–µ–º–æ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç NB –Ω–∞ **+10-20 p.p.**\n",
        "\n",
        "–î–∞–ª—å–Ω–µ–π—à–∏–µ —à–∞–≥–∏:\n",
        "1. –î–æ–±–∞–≤–∏—Ç—å Logistic Regression + TF-IDF.\n",
        "2. –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å DistilBERT –¥–ª—è fair-—Å—Ä–∞–≤–Ω–µ–Ω–∏—è.\n",
        "3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ baseline-—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ README / –æ—Ç—á—ë—Ç.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
