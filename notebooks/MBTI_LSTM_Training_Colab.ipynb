{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mueqee/MBTI-LSTM/blob/main/notebooks/MBTI_LSTM_Training_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmVTOks0lInq"
   },
   "source": [
    "# MBTI-LSTM. Обучение модели. Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "Классификация типов личности MBTI на основе текстов из социальных сетей с использованием LSTM архитектуры.\n",
    "\n",
    "**Архитектура модели:**\n",
    "- Embedding (300d) → BiLSTM(128) → BiLSTM(64) → Dropout(0.2) → FC(64, ReLU) → Output(4, Sigmoid)\n",
    "- 4 бинарных классификатора для дихотомий: I/E, N/S, T/F, J/P\n",
    "\n",
    "**Ожидаемый результат:** 80-86% accuracy\n",
    "\n",
    "---\n",
    "\n",
    "vers. 1.1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFBGjSU2lIns"
   },
   "source": [
    "## 1. GPU\n",
    "\n",
    "Настройка:\n",
    "1. Runtime → Change runtime type\n",
    "2. Hardware accelerator → GPU (T4)\n",
    "3. Save\n",
    "\n",
    "Проверка GPU через import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BokRJCfblIns"
   },
   "outputs": [],
   "source": [
    "# Проверка GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"⚠️ GPU не обнаружен!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q75FtNH2hO8N"
   },
   "source": [
    "## 2. Клон репозиторий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNAwfwDslInt"
   },
   "outputs": [],
   "source": [
    "# Клонировать репозиторий\n",
    "!git clone https://github.com/mueqee/MBTI-LSTM.git\n",
    "%cd MBTI-LSTM\n",
    "\n",
    "# Проверить структуру\n",
    "!ls -la\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f94f0fc1"
   },
   "source": [
    "## 3. Установка зависимостей\n",
    "через pip install -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eILsTMTOlInu"
   },
   "outputs": [],
   "source": [
    "# Установить зависимости\n",
    "%pip install -q -r requirements.txt\n",
    "%pip install -q -e .\n",
    "\n",
    "# Скачать NLTK данные\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"✅ Зависимости установлены!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"ipykernel==6.17.1\" \"jupyter-client<8\" \"notebook<7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy7ywnJslInv"
   },
   "source": [
    "## 4. Загрузка датасета Kaggle\n",
    "Получить API токен через https://www.kaggle.com/settings -> API -> Create New Token\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTKDUeTflInv"
   },
   "outputs": [],
   "source": [
    "# 1. Получить API токен: https://www.kaggle.com/settings -> API -> Create New Token\n",
    "# 2. Загрузить kaggle.json\n",
    "\n",
    "from google.colab import files\n",
    "print(\"Загрузите файл kaggle.json:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Настроить Kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Скачать датасет\n",
    "!kaggle datasets download -d datasnaek/mbti-type\n",
    "!unzip -q mbti-type.zip -d data/raw/\n",
    "!rm mbti-type.zip\n",
    "!mv data/raw/mbti_1.csv data/raw/mbti_dataset.csv\n",
    "\n",
    "print(\"Датасет скачан с Kaggle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d3be248"
   },
   "source": [
    "## 5. Анализ датасета\n",
    "Загрузить датасет\n",
    "Через import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5PodklelInx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузить датасет\n",
    "df = pd.read_csv('data/raw/mbti_dataset.csv')\n",
    "\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Колонки: {df.columns.tolist()}\")\n",
    "print(f\"\\n Распределение MBTI типов:\")\n",
    "type_counts = df['type'].value_counts()\n",
    "print(type_counts)\n",
    "\n",
    "# Визуализация\n",
    "plt.figure(figsize=(12, 6))\n",
    "type_counts.plot(kind='bar', color='steelblue')\n",
    "plt.title('Распределение MBTI типов в датасете')\n",
    "plt.xlabel('MBTI тип')\n",
    "plt.ylabel('Количество')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nПример поста (первые 200 символов):\")\n",
    "print(df['posts'].iloc[0][:200] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPMfR4GE8qbo"
   },
   "source": [
    "## 6. Обновление репозитория\n",
    "\n",
    "Подтягиваем свежие изменения из гитхаба командой чтобы синхронизировать код перед дальнейшими шагами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VARnue8y9LTu"
   },
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLg2nnClhO8Z"
   },
   "source": [
    "## 7. Поиск гиперпараметров через Optuna\n",
    "\n",
    "Вместо ручного подбора параметров используем байесовскую оптимизацию.\n",
    "\n",
    "Установка через pip install -q optuna optuna-dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlZtAZwkhO8Z"
   },
   "outputs": [],
   "source": [
    "# Установка Optuna для поиска гиперпараметров\n",
    "%pip install -q optuna optuna-dashboard\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"✅ Optuna установлен для умного поиска гиперпараметров\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba76d765"
   },
   "source": [
    "## 8. Импорт модулей\n",
    "Через import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4lM50lWhO8a"
   },
   "outputs": [],
   "source": [
    "# Импорт модулей проекта\n",
    "import sys\n",
    "sys.path.append('/content/MBTI-LSTM')\n",
    "\n",
    "from src.data.preprocessor import MBTIPostPreprocessor\n",
    "from src.data.dataset import create_data_loaders\n",
    "from src.models.lstm_model import LSTMMBTIClassifier\n",
    "from src.training.trainer import MBTITrainer\n",
    "from src.training.metrics import MBTIMetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "print(\"✅ Модули проекта импортированы\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "275b85d9"
   },
   "source": [
    "## 9. Гиперпараметры для поиска\n",
    "objective() в Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mSlSL9nhO8b"
   },
   "outputs": [],
   "source": [
    "def objective(trial: Trial) -> float:\n",
    "    \"\"\"\n",
    "    Целевая функция для Optuna.\n",
    "    Возвращает отрицательную val_accuracy (минимизируем).\n",
    "    \"\"\"\n",
    "    \n",
    "    config = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 5e-3, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'hidden_dim_1': trial.suggest_categorical('hidden_dim_1', [64, 128, 256]),\n",
    "        'hidden_dim_2': trial.suggest_categorical('hidden_dim_2', [32, 64, 128]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.4, step=0.05),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'adamw', 'rmsprop']),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0.0, 0.001, step=0.0001),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTrial {trial.number}: {config['optimizer']}, LR={config['learning_rate']:.4f}, BS={config['batch_size']}\")\n",
    "    \n",
    "    try:\n",
    "        preprocessor = MBTIPostPreprocessor(\n",
    "            lowercase=True,\n",
    "            remove_urls=True,\n",
    "            remove_special_chars=True,\n",
    "            remove_stopwords=True,\n",
    "            lemmatize=True\n",
    "        )\n",
    "        \n",
    "        loaders = create_data_loaders(\n",
    "            df,\n",
    "            preprocessor=preprocessor,\n",
    "            max_length=300,\n",
    "            batch_size=config['batch_size'],\n",
    "            val_split=0.15,\n",
    "            test_split=0.15,\n",
    "            num_workers=2\n",
    "        )\n",
    "        train_loader = loaders['train']\n",
    "        val_loader = loaders['val']\n",
    "        vocab = loaders['vocabulary']\n",
    "        \n",
    "        model = LSTMMBTIClassifier(\n",
    "            vocab_size=len(vocab),\n",
    "            embedding_dim=200,\n",
    "            hidden_dim_1=config['hidden_dim_1'],\n",
    "            hidden_dim_2=config['hidden_dim_2'],\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "        \n",
    "        if config['optimizer'] == 'adam':\n",
    "            optimizer = torch.optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        elif config['optimizer'] == 'adamw':\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        else:\n",
    "            optimizer = torch.optim.RMSprop(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        trainer = MBTITrainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=nn.BCELoss(),\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            checkpoint_dir='tmp_optuna',\n",
    "            save_best_only=False,\n",
    "            early_stopping_patience=2\n",
    "        )\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        for epoch in range(1, 6):\n",
    "            trainer.current_epoch = epoch - 1\n",
    "            train_metrics = trainer.train_epoch()\n",
    "            trainer.current_epoch = epoch - 1\n",
    "            val_metrics = trainer.validate()\n",
    "            \n",
    "            train_loss = train_metrics['loss']\n",
    "            train_acc = train_metrics['overall_accuracy']\n",
    "            val_loss = val_metrics['loss']\n",
    "            val_acc = val_metrics['overall_accuracy']\n",
    "            \n",
    "            print(\n",
    "                f\"    Эпоха {epoch}: train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, \"\n",
    "                f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\"\n",
    "            )\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "            \n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune():\n",
    "                print(f\"  ⚠️ Pruning на эпохе {epoch}\")\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        print(f\"  ✅ Лучшая val_acc: {best_val_acc:.4f}\")\n",
    "        return -best_val_acc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Ошибка: {e}\")\n",
    "        return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38cd9a03"
   },
   "source": [
    "## 10. Optuna study\n",
    "Через study = optuna.create_study()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-s-HL2PKhO8c"
   },
   "outputs": [],
   "source": [
    "# Создаём Optuna study\n",
    "study = optuna.create_study(\n",
    "    study_name='mbti_lstm_hp_search',\n",
    "    direction='minimize',\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=3,\n",
    "        n_warmup_steps=2,\n",
    "        interval_steps=1\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ПОИСК ГИПЕРПАРАМЕТРОВ ЧЕРЕЗ OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "print(\"Количество попыток: 15 \")\n",
    "print(\"Эпох на попытку: 5\")\n",
    "print(\"Время: ~30-40 минут\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1858608f"
   },
   "source": [
    "## 11. Оптимизация\n",
    "Через study.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOaEvgXMhO8d"
   },
   "outputs": [],
   "source": [
    "# Запуск оптимизации\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=15,  \n",
    "    gc_after_trial=True,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6ac5c01"
   },
   "source": [
    "## 12. Вывод и визуализация результатов поиска\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2HD9shphO8e"
   },
   "outputs": [],
   "source": [
    "# Анализ результатов поиска\n",
    "print(\"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ ПОИСКА ГИПЕРПАРАМЕТРОВ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\\\nЛучшая accuracy: {-study.best_value:.4f}\")\n",
    "print(\"\\\\nЛучшие параметры:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Сохраняем лучшую конфигурацию\n",
    "best_config = {\n",
    "    'accuracy': -study.best_value,\n",
    "    'params': study.best_params,\n",
    "    'n_trials': len(study.trials),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "config_filename = f'best_config_{datetime.now():%Y%m%d_%H%M}.json'\n",
    "with open(config_filename, 'w') as f:\n",
    "    json.dump(best_config, f, indent=2)\n",
    "\n",
    "print(f\"\\\\n✅ Конфигурация сохранена: {config_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4A_mH_ahO8e"
   },
   "outputs": [],
   "source": [
    "# Визуализация результатов поиска\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. История оптимизации\n",
    "trials_df = study.trials_dataframe()\n",
    "axes[0,0].plot(trials_df.index, -trials_df['value'], 'b-', alpha=0.5, label='Trial accuracy')\n",
    "axes[0,0].plot(trials_df.index, (-trials_df['value']).cummax(), 'r-', linewidth=2, label='Best so far')\n",
    "axes[0,0].set_xlabel('Trial')\n",
    "axes[0,0].set_ylabel('Validation Accuracy')\n",
    "axes[0,0].set_title('История оптимизации')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Важность параметров\n",
    "importances = optuna.importance.get_param_importances(study)\n",
    "params = list(importances.keys())\n",
    "values = list(importances.values())\n",
    "axes[0,1].barh(params, values)\n",
    "axes[0,1].set_xlabel('Важность')\n",
    "axes[0,1].set_title('Важность гиперпараметров')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Learning Rate vs Accuracy\n",
    "if 'params_learning_rate' in trials_df.columns:\n",
    "    axes[1,0].scatter(trials_df['params_learning_rate'], -trials_df['value'], alpha=0.6)\n",
    "    axes[1,0].set_xlabel('Learning Rate')\n",
    "    axes[1,0].set_ylabel('Accuracy')\n",
    "    axes[1,0].set_title('Learning Rate vs Accuracy')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Optimizer comparison\n",
    "if 'params_optimizer' in trials_df.columns:\n",
    "    optimizer_stats = trials_df.groupby('params_optimizer')['value'].agg(['mean', 'std'])\n",
    "    optimizer_stats['mean'] = -optimizer_stats['mean']\n",
    "    optimizer_stats['std'] = optimizer_stats['std']\n",
    "\n",
    "    axes[1,1].bar(optimizer_stats.index, optimizer_stats['mean'],\n",
    "                  yerr=optimizer_stats['std'], capsize=5)\n",
    "    axes[1,1].set_ylabel('Accuracy')\n",
    "    axes[1,1].set_title('Сравнение оптимизаторов')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\n📊 Визуализация результатов поиска готова!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXtotcADhO8f"
   },
   "source": [
    "## 13. Проверка лучших параметров\n",
    "\n",
    "Через best_params = study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZwDGEO8hO8f"
   },
   "outputs": [],
   "source": [
    "# Используем лучшие параметры для финального обучения\n",
    "best_params = study.best_params\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ФИНАЛЬНОЕ ОБУЧЕНИЕ С ЛУЧШИМИ ПАРАМЕТРАМИ\")\n",
    "print(\"=\"*60)\n",
    "print(\"Параметры:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "preprocessor = MBTIPostPreprocessor(\n",
    "    lowercase=True,\n",
    "    remove_urls=True,\n",
    "    remove_special_chars=True,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=True\n",
    ")\n",
    "\n",
    "loaders = create_data_loaders(\n",
    "    df,\n",
    "    preprocessor=preprocessor,\n",
    "    max_length=500,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    val_split=0.15,\n",
    "    test_split=0.15,\n",
    "    num_workers=2\n",
    ")\n",
    "train_loader = loaders['train']\n",
    "val_loader = loaders['val']\n",
    "test_loader = loaders['test']\n",
    "vocab = loaders['vocabulary']\n",
    "\n",
    "final_model = LSTMMBTIClassifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=300,\n",
    "    hidden_dim_1=best_params['hidden_dim_1'],\n",
    "    hidden_dim_2=best_params['hidden_dim_2'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "\n",
    "if best_params['optimizer'] == 'adam':\n",
    "    final_optimizer = torch.optim.Adam(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "elif best_params['optimizer'] == 'adamw':\n",
    "    final_optimizer = torch.optim.AdamW(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "else:\n",
    "    final_optimizer = torch.optim.RMSprop(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "\n",
    "num_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "print()\n",
    "print(f\"Модель создана: {num_params:,} параметров\")\n",
    "print(f\"Оптимизатор: {best_params['optimizer']}\")\n",
    "print(f\"Learning rate: {best_params['learning_rate']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5501af70"
   },
   "source": [
    "## 14. Финальное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_CMeE5LhO8g"
   },
   "outputs": [],
   "source": [
    "# Финальное обучение\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "final_trainer = MBTITrainer(\n",
    "    model=final_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=nn.BCELoss(),\n",
    "    optimizer=final_optimizer,\n",
    "    device=device,\n",
    "    checkpoint_dir='checkpoints/optimized',\n",
    "    save_best_only=True,\n",
    "    early_stopping_patience=5\n",
    ")\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "train_history = {'loss': [], 'acc': []}\n",
    "val_history = {'loss': [], 'acc': []}\n",
    "print(f\"Начинаем финальное обучение на {NUM_EPOCHS} эпох...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "BEST_MODEL_PATH = 'best_optimized_model.pth'\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    final_trainer.current_epoch = epoch - 1\n",
    "    train_metrics = final_trainer.train_epoch()\n",
    "    final_trainer.current_epoch = epoch - 1\n",
    "    val_metrics = final_trainer.validate()\n",
    "\n",
    "    train_loss = train_metrics['loss']\n",
    "    train_acc = train_metrics['overall_accuracy']\n",
    "    val_loss = val_metrics['loss']\n",
    "    val_acc = val_metrics['overall_accuracy']\n",
    "\n",
    "    train_history['loss'].append(train_loss)\n",
    "    train_history['acc'].append(train_acc)\n",
    "    val_history['loss'].append(val_loss)\n",
    "    val_history['acc'].append(val_acc)\n",
    "\n",
    "    dichotomy_names = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "    val_dichotomies = {name: val_metrics[f'{name}_accuracy'] for name in dichotomy_names}\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:2d}/{NUM_EPOCHS}: \"\n",
    "        f\"Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | \"\n",
    "        f\"Val Loss={val_loss:.4f}, Acc={val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\n",
    "            \"  Дихотомии: \" + \", \".join(\n",
    "                [f\"{name}={val_dichotomies[name]:.3f}\" for name in dichotomy_names]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': final_model.state_dict(),\n",
    "            'optimizer_state_dict': final_optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'config': best_params\n",
    "        }, BEST_MODEL_PATH)\n",
    "        print(f\"  ✅ Новая лучшая модель! (Val Acc: {val_acc:.4f})\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Обучение завершено! Лучшая accuracy: {best_val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec898298"
   },
   "source": [
    "## 15. Тестирование на тестовой выборке\n",
    "Чрез test_loss, test_acc, test_dichotomies = final_trainer.validate(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMYqjTabhO8i"
   },
   "outputs": [],
   "source": [
    "# Тестирование на тестовой выборке\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def evaluate_loader(loader):\n",
    "    final_model.eval()\n",
    "    metrics = MBTIMetrics(device=device)\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            lengths = batch['length'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = final_model(input_ids, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_size = input_ids.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            metrics.update((outputs > 0.5).float(), labels, outputs)\n",
    "\n",
    "    results = metrics.compute()\n",
    "    results['loss'] = total_loss / max(total_samples, 1)\n",
    "    return results\n",
    "\n",
    "test_metrics = evaluate_loader(test_loader)\n",
    "\n",
    "test_loss = test_metrics['loss']\n",
    "test_acc = test_metrics['overall_accuracy']\n",
    "\n",
    "dichotomy_names = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "test_dichotomies = {name: test_metrics[f'{name}_accuracy'] for name in dichotomy_names}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"РЕЗУЛЬТАТЫ НА ТЕСТОВОЙ ВЫБОРКЕ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"Точность по дихотомиям:\")\n",
    "for key, value in test_dichotomies.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(train_history['loss'], label='Train Loss')\n",
    "axes[0].plot(val_history['loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(train_history['acc'], label='Train Acc')\n",
    "axes[1].plot(val_history['acc'], label='Val Acc')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77b54cbd"
   },
   "source": [
    "## 16. Выгрузка в Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3gwTk_yhO8j"
   },
   "outputs": [],
   "source": [
    "# Сохранение результатов в Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Создаём папку для результатов\n",
    "import os\n",
    "import shutil\n",
    "save_dir = '/content/drive/MyDrive/MBTI-LSTM-Optimized-Results'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Сохраняем файлы\n",
    "shutil.copy('best_optimized_model.pth', save_dir)\n",
    "shutil.copy(config_filename, save_dir)\n",
    "\n",
    "# Сохраняем результаты\n",
    "results = {\n",
    "    'best_hyperparams': best_params,\n",
    "    'best_val_acc': float(best_val_acc),\n",
    "    'test_acc': float(test_acc),\n",
    "    'test_dichotomies': {k: float(v) for k, v in test_dichotomies.items()},\n",
    "    'num_trials': len(study.trials),\n",
    "    'training_epochs': NUM_EPOCHS,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "results_filename = f'optimized_results_{datetime.now():%Y%m%d_%H%M}.json'\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "shutil.copy(results_filename, save_dir)\n",
    "\n",
    "print(f\"\\\\n✅ Все результаты сохранены в Google Drive: {save_dir}\")\n",
    "print(f\"✅ Модель: best_optimized_model.pth\")\n",
    "print(f\"✅ Конфигурация: {config_filename}\")\n",
    "print(f\"✅ Результаты: {results_filename}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"ИТОГОВЫЕ РЕЗУЛЬТАТЫ\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Лучшая Val Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"\\\\nУлучшение по сравнению с базовой моделью:\")\n",
    "print(f\"  Базовая модель: ~71%\")\n",
    "print(f\"  Оптимизированная: {test_acc:.1%}\")\n",
    "print(f\"  Прирост: +{test_acc*100-71:.1f}%\")\n",
    "\n",
    "if test_acc > 0.75:\n",
    "    print(\"\\\\n🎉 Отличный результат! Модель готова к production!\")\n",
    "elif test_acc > 0.72:\n",
    "    print(\"\\\\n✅ Хороший результат! Можно добавить attention для улучшения.\")\n",
    "else:\n",
    "    print(\"\\\\n⚠️ Результат можно улучшить. Попробуйте:\")\n",
    "    print(\"  - Увеличить количество эпох до 50\")\n",
    "    print(\"  - Добавить attention механизм\")\n",
    "    print(\"  - Использовать pretrained embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9956728"
   },
   "source": [
    "## 17. Или удалить и клон снова:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9X7L0ty9SGp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Или удалить и клон снова:\n",
    "!rm -rf MBTI-LSTM\n",
    "!git clone https://github.com/mueqee/MBTI-LSTM.git\n",
    "%cd MBTI-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fedf6a10"
   },
   "source": [
    "## 18. Быстрый тест на 2 эпохи\n",
    "Через !python scripts/train.py \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwJMcYy9lInx"
   },
   "outputs": [],
   "source": [
    "!python scripts/train.py \\\n",
    "    --data_path data/raw/mbti_dataset.csv \\\n",
    "    --num_epochs 2 \\\n",
    "    --batch_size 32 \\\n",
    "    --checkpoint_dir checkpoints/quick_test\n",
    "\n",
    "print(\"\\n✅ Тест пройден! Модель обучается корректно\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKq3F7GdlIny"
   },
   "source": [
    "## 19. Обучение на 50 эпох\n",
    "\n",
    "Запуск тренировочного скрипта из CLI\n",
    " scripts/train.py, чтобы проверить полноценный пайплайн обучения из репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljertD-alIny"
   },
   "outputs": [],
   "source": [
    "print(\"Запуск финального обучения на 50 эпох...\\n\")\n",
    "\n",
    "!python scripts/train.py \\\n",
    "    --data_path data/raw/mbti_dataset.csv \\\n",
    "    --num_epochs 50 \\\n",
    "    --batch_size 64 \\\n",
    "    --learning_rate 0.001 \\\n",
    "    --optimizer adam \\\n",
    "    --hidden_dim_1 128 \\\n",
    "    --hidden_dim_2 64 \\\n",
    "    --dropout 0.2 \\\n",
    "    --max_length 750 \\\n",
    "    --balance_classes \\\n",
    "    --num_workers 4 \\\n",
    "    --early_stopping_patience 7 \\\n",
    "    --checkpoint_dir checkpoints/final_model\n",
    "\n",
    "print(\"\\n✅ Обучение завершено!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ac030f0"
   },
   "source": [
    "## 20. Сохранение результатов\n",
    "Описание: from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruR7GV2zlIny"
   },
   "outputs": [],
   "source": [
    "# Сохранить в Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!mkdir -p '/content/drive/MyDrive/MBTI-LSTM-Results'\n",
    "!cp -r checkpoints/final_model '/content/drive/MyDrive/MBTI-LSTM-Results/'\n",
    "!cp -r checkpoints/quick_test '/content/drive/MyDrive/MBTI-LSTM-Results/'\n",
    "\n",
    "print(\"✅ Результаты сохранены в Google Drive!\")\n",
    "print(\"Путь: /content/drive/MyDrive/MBTI-LSTM-Results/\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "state": {},
   "version_major": 2,
   "version_minor": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
