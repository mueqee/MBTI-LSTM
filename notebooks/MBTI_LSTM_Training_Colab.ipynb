{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mueqee/MBTI-LSTM/blob/main/notebooks/MBTI_LSTM_Training_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmVTOks0lInq"
   },
   "source": [
    "# MBTI-LSTM. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏. Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –ª–∏—á–Ω–æ—Å—Ç–∏ MBTI –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LSTM –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã.\n",
    "\n",
    "**–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:**\n",
    "- Embedding (300d) ‚Üí BiLSTM(128) ‚Üí BiLSTM(64) ‚Üí Dropout(0.2) ‚Üí FC(64, ReLU) ‚Üí Output(4, Sigmoid)\n",
    "- 4 –±–∏–Ω–∞—Ä–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –¥–∏—Ö–æ—Ç–æ–º–∏–π: I/E, N/S, T/F, J/P\n",
    "\n",
    "**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:** 80-86% accuracy\n",
    "\n",
    "---\n",
    "\n",
    "vers. 1.1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kFBGjSU2lIns"
   },
   "source": [
    "## 1. GPU\n",
    "\n",
    "–ù–∞—Å—Ç—Ä–æ–π–∫–∞:\n",
    "1. Runtime ‚Üí Change runtime type\n",
    "2. Hardware accelerator ‚Üí GPU (T4)\n",
    "3. Save\n",
    "\n",
    "–ü—Ä–æ–≤–µ—Ä–∫–∞ GPU —á–µ—Ä–µ–∑ import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BokRJCfblIns"
   },
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q75FtNH2hO8N"
   },
   "source": [
    "## 2. –ö–ª–æ–Ω —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNAwfwDslInt"
   },
   "outputs": [],
   "source": [
    "# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π\n",
    "!git clone https://github.com/mueqee/MBTI-LSTM.git\n",
    "%cd MBTI-LSTM\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É\n",
    "!ls -la\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f94f0fc1"
   },
   "source": [
    "## 3. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π\n",
    "—á–µ—Ä–µ–∑ pip install -q -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eILsTMTOlInu"
   },
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏\n",
    "%pip install -q -r requirements.txt\n",
    "%pip install -q -e .\n",
    "\n",
    "# –°–∫–∞—á–∞—Ç—å NLTK –¥–∞–Ω–Ω—ã–µ\n",
    "import nltk\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "print(\"‚úÖ –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q \"ipykernel==6.17.1\" \"jupyter-client<8\" \"notebook<7\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy7ywnJslInv"
   },
   "source": [
    "## 4. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ Kaggle\n",
    "–ü–æ–ª—É—á–∏—Ç—å API —Ç–æ–∫–µ–Ω —á–µ—Ä–µ–∑ https://www.kaggle.com/settings -> API -> Create New Token\n",
    "from google.colab import files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTKDUeTflInv"
   },
   "outputs": [],
   "source": [
    "# 1. –ü–æ–ª—É—á–∏—Ç—å API —Ç–æ–∫–µ–Ω: https://www.kaggle.com/settings -> API -> Create New Token\n",
    "# 2. –ó–∞–≥—Ä—É–∑–∏—Ç—å kaggle.json\n",
    "\n",
    "from google.colab import files\n",
    "print(\"–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª kaggle.json:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# –°–∫–∞—á–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "!kaggle datasets download -d datasnaek/mbti-type\n",
    "!unzip -q mbti-type.zip -d data/raw/\n",
    "!rm mbti-type.zip\n",
    "!mv data/raw/mbti_1.csv data/raw/mbti_dataset.csv\n",
    "\n",
    "print(\"–î–∞—Ç–∞—Å–µ—Ç —Å–∫–∞—á–∞–Ω —Å Kaggle\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d3be248"
   },
   "source": [
    "## 5. –ê–Ω–∞–ª–∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "–ß–µ—Ä–µ–∑ import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5PodklelInx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "df = pd.read_csv('data/raw/mbti_dataset.csv')\n",
    "\n",
    "print(f\"–†–∞–∑–º–µ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {df.shape}\")\n",
    "print(f\"–ö–æ–ª–æ–Ω–∫–∏: {df.columns.tolist()}\")\n",
    "print(f\"\\n –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ MBTI —Ç–∏–ø–æ–≤:\")\n",
    "type_counts = df['type'].value_counts()\n",
    "print(type_counts)\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "plt.figure(figsize=(12, 6))\n",
    "type_counts.plot(kind='bar', color='steelblue')\n",
    "plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ MBTI —Ç–∏–ø–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ')\n",
    "plt.xlabel('MBTI —Ç–∏–ø')\n",
    "plt.ylabel('–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n–ü—Ä–∏–º–µ—Ä –ø–æ—Å—Ç–∞ (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):\")\n",
    "print(df['posts'].iloc[0][:200] + \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPMfR4GE8qbo"
   },
   "source": [
    "## 6. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è\n",
    "\n",
    "–ü–æ–¥—Ç—è–≥–∏–≤–∞–µ–º —Å–≤–µ–∂–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∏–∑ –≥–∏—Ç—Ö–∞–±–∞ –∫–æ–º–∞–Ω–¥–æ–π —á—Ç–æ–±—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ –ø–µ—Ä–µ–¥ –¥–∞–ª—å–Ω–µ–π—à–∏–º–∏ —à–∞–≥–∞–º–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VARnue8y9LTu"
   },
   "outputs": [],
   "source": [
    "!git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLg2nnClhO8Z"
   },
   "source": [
    "## 7. –ü–æ–∏—Å–∫ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —á–µ—Ä–µ–∑ Optuna\n",
    "\n",
    "–í–º–µ—Å—Ç–æ —Ä—É—á–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–π–µ—Å–æ–≤—Å–∫—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é.\n",
    "\n",
    "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ —á–µ—Ä–µ–∑ pip install -q optuna optuna-dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SlZtAZwkhO8Z"
   },
   "outputs": [],
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Optuna –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "%pip install -q optuna optuna-dashboard\n",
    "\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"‚úÖ Optuna —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ba76d765"
   },
   "source": [
    "## 8. –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π\n",
    "–ß–µ—Ä–µ–∑ import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4lM50lWhO8a"
   },
   "outputs": [],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç –º–æ–¥—É–ª–µ–π –ø—Ä–æ–µ–∫—Ç–∞\n",
    "import sys\n",
    "sys.path.append('/content/MBTI-LSTM')\n",
    "\n",
    "from src.data.preprocessor import MBTIPostPreprocessor\n",
    "from src.data.dataset import create_data_loaders\n",
    "from src.models.lstm_model import LSTMMBTIClassifier\n",
    "from src.training.trainer import MBTITrainer\n",
    "from src.training.metrics import MBTIMetrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from google.colab import output\n",
    "output.enable_custom_widget_manager()\n",
    "\n",
    "print(\"‚úÖ –ú–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "275b85d9"
   },
   "source": [
    "## 9. –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞\n",
    "objective() –≤ Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mSlSL9nhO8b"
   },
   "outputs": [],
   "source": [
    "def objective(trial: Trial) -> float:\n",
    "    \"\"\"\n",
    "    –¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Optuna.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—É—é val_accuracy (–º–∏–Ω–∏–º–∏–∑–∏—Ä—É–µ–º).\n",
    "    \"\"\"\n",
    "    \n",
    "    config = {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 5e-3, log=True),\n",
    "        'batch_size': trial.suggest_categorical('batch_size', [16, 32, 64]),\n",
    "        'hidden_dim_1': trial.suggest_categorical('hidden_dim_1', [64, 128, 256]),\n",
    "        'hidden_dim_2': trial.suggest_categorical('hidden_dim_2', [32, 64, 128]),\n",
    "        'dropout': trial.suggest_float('dropout', 0.1, 0.4, step=0.05),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'adamw', 'rmsprop']),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 0.0, 0.001, step=0.0001),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nTrial {trial.number}: {config['optimizer']}, LR={config['learning_rate']:.4f}, BS={config['batch_size']}\")\n",
    "    \n",
    "    try:\n",
    "        preprocessor = MBTIPostPreprocessor(\n",
    "            lowercase=True,\n",
    "            remove_urls=True,\n",
    "            remove_special_chars=True,\n",
    "            remove_stopwords=True,\n",
    "            lemmatize=True\n",
    "        )\n",
    "        \n",
    "        loaders = create_data_loaders(\n",
    "            df,\n",
    "            preprocessor=preprocessor,\n",
    "            max_length=300,\n",
    "            batch_size=config['batch_size'],\n",
    "            val_split=0.15,\n",
    "            test_split=0.15,\n",
    "            num_workers=2\n",
    "        )\n",
    "        train_loader = loaders['train']\n",
    "        val_loader = loaders['val']\n",
    "        vocab = loaders['vocabulary']\n",
    "        \n",
    "        model = LSTMMBTIClassifier(\n",
    "            vocab_size=len(vocab),\n",
    "            embedding_dim=200,\n",
    "            hidden_dim_1=config['hidden_dim_1'],\n",
    "            hidden_dim_2=config['hidden_dim_2'],\n",
    "            dropout=config['dropout']\n",
    "        )\n",
    "        \n",
    "        if config['optimizer'] == 'adam':\n",
    "            optimizer = torch.optim.Adam(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        elif config['optimizer'] == 'adamw':\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        else:\n",
    "            optimizer = torch.optim.RMSprop(\n",
    "                model.parameters(),\n",
    "                lr=config['learning_rate'],\n",
    "                weight_decay=config['weight_decay']\n",
    "            )\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        trainer = MBTITrainer(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=nn.BCELoss(),\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            checkpoint_dir='tmp_optuna',\n",
    "            save_best_only=False,\n",
    "            early_stopping_patience=2\n",
    "        )\n",
    "        \n",
    "        best_val_acc = 0.0\n",
    "        for epoch in range(1, 6):\n",
    "            trainer.current_epoch = epoch - 1\n",
    "            train_metrics = trainer.train_epoch()\n",
    "            trainer.current_epoch = epoch - 1\n",
    "            val_metrics = trainer.validate()\n",
    "            \n",
    "            train_loss = train_metrics['loss']\n",
    "            train_acc = train_metrics['overall_accuracy']\n",
    "            val_loss = val_metrics['loss']\n",
    "            val_acc = val_metrics['overall_accuracy']\n",
    "            \n",
    "            print(\n",
    "                f\"    –≠–ø–æ—Ö–∞ {epoch}: train_loss={train_loss:.4f}, train_acc={train_acc:.4f}, \"\n",
    "                f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\"\n",
    "            )\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "            \n",
    "            trial.report(val_acc, epoch)\n",
    "            if trial.should_prune():\n",
    "                print(f\"  ‚ö†Ô∏è Pruning –Ω–∞ —ç–ø–æ—Ö–µ {epoch}\")\n",
    "                raise optuna.TrialPruned()\n",
    "        \n",
    "        print(f\"  ‚úÖ –õ—É—á—à–∞—è val_acc: {best_val_acc:.4f}\")\n",
    "        return -best_val_acc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå –û—à–∏–±–∫–∞: {e}\")\n",
    "        return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38cd9a03"
   },
   "source": [
    "## 10. Optuna study\n",
    "–ß–µ—Ä–µ–∑ study = optuna.create_study()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-s-HL2PKhO8c"
   },
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞—ë–º Optuna study\n",
    "study = optuna.create_study(\n",
    "    study_name='mbti_lstm_hp_search',\n",
    "    direction='minimize',\n",
    "    pruner=optuna.pruners.MedianPruner(\n",
    "        n_startup_trials=3,\n",
    "        n_warmup_steps=2,\n",
    "        interval_steps=1\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"–ü–û–ò–°–ö –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í –ß–ï–†–ï–ó OPTUNA\")\n",
    "print(\"=\"*60)\n",
    "print(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫: 15 \")\n",
    "print(\"–≠–ø–æ—Ö –Ω–∞ –ø–æ–ø—ã—Ç–∫—É: 5\")\n",
    "print(\"–í—Ä–µ–º—è: ~30-40 –º–∏–Ω—É—Ç\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1858608f"
   },
   "source": [
    "## 11. –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è\n",
    "–ß–µ—Ä–µ–∑ study.optimize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOaEvgXMhO8d"
   },
   "outputs": [],
   "source": [
    "# –ó–∞–ø—É—Å–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=15,  \n",
    "    gc_after_trial=True,\n",
    "    show_progress_bar=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6ac5c01"
   },
   "source": [
    "## 12. –í—ã–≤–æ–¥ –∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M2HD9shphO8e"
   },
   "outputs": [],
   "source": [
    "# –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "print(\"=\"*60)\n",
    "print(\"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\\\n–õ—É—á—à–∞—è accuracy: {-study.best_value:.4f}\")\n",
    "print(\"\\\\n–õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é\n",
    "best_config = {\n",
    "    'accuracy': -study.best_value,\n",
    "    'params': study.best_params,\n",
    "    'n_trials': len(study.trials),\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "config_filename = f'best_config_{datetime.now():%Y%m%d_%H%M}.json'\n",
    "with open(config_filename, 'w') as f:\n",
    "    json.dump(best_config, f, indent=2)\n",
    "\n",
    "print(f\"\\\\n‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {config_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4A_mH_ahO8e"
   },
   "outputs": [],
   "source": [
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏\n",
    "trials_df = study.trials_dataframe()\n",
    "axes[0,0].plot(trials_df.index, -trials_df['value'], 'b-', alpha=0.5, label='Trial accuracy')\n",
    "axes[0,0].plot(trials_df.index, (-trials_df['value']).cummax(), 'r-', linewidth=2, label='Best so far')\n",
    "axes[0,0].set_xlabel('Trial')\n",
    "axes[0,0].set_ylabel('Validation Accuracy')\n",
    "axes[0,0].set_title('–ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏')\n",
    "axes[0,0].legend()\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. –í–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "importances = optuna.importance.get_param_importances(study)\n",
    "params = list(importances.keys())\n",
    "values = list(importances.values())\n",
    "axes[0,1].barh(params, values)\n",
    "axes[0,1].set_xlabel('–í–∞–∂–Ω–æ—Å—Ç—å')\n",
    "axes[0,1].set_title('–í–∞–∂–Ω–æ—Å—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Learning Rate vs Accuracy\n",
    "if 'params_learning_rate' in trials_df.columns:\n",
    "    axes[1,0].scatter(trials_df['params_learning_rate'], -trials_df['value'], alpha=0.6)\n",
    "    axes[1,0].set_xlabel('Learning Rate')\n",
    "    axes[1,0].set_ylabel('Accuracy')\n",
    "    axes[1,0].set_title('Learning Rate vs Accuracy')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Optimizer comparison\n",
    "if 'params_optimizer' in trials_df.columns:\n",
    "    optimizer_stats = trials_df.groupby('params_optimizer')['value'].agg(['mean', 'std'])\n",
    "    optimizer_stats['mean'] = -optimizer_stats['mean']\n",
    "    optimizer_stats['std'] = optimizer_stats['std']\n",
    "\n",
    "    axes[1,1].bar(optimizer_stats.index, optimizer_stats['mean'],\n",
    "                  yerr=optimizer_stats['std'], capsize=5)\n",
    "    axes[1,1].set_ylabel('Accuracy')\n",
    "    axes[1,1].set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\\\nüìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≥–æ—Ç–æ–≤–∞!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXtotcADhO8f"
   },
   "source": [
    "## 13. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "\n",
    "–ß–µ—Ä–µ–∑ best_params = study.best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZwDGEO8hO8f"
   },
   "outputs": [],
   "source": [
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "best_params = study.best_params\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"–§–ò–ù–ê–õ–¨–ù–û–ï –û–ë–£–ß–ï–ù–ò–ï –° –õ–£–ß–®–ò–ú–ò –ü–ê–†–ê–ú–ï–¢–†–ê–ú–ò\")\n",
    "print(\"=\"*60)\n",
    "print(\"–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "preprocessor = MBTIPostPreprocessor(\n",
    "    lowercase=True,\n",
    "    remove_urls=True,\n",
    "    remove_special_chars=True,\n",
    "    remove_stopwords=True,\n",
    "    lemmatize=True\n",
    ")\n",
    "\n",
    "loaders = create_data_loaders(\n",
    "    df,\n",
    "    preprocessor=preprocessor,\n",
    "    max_length=500,\n",
    "    batch_size=best_params['batch_size'],\n",
    "    val_split=0.15,\n",
    "    test_split=0.15,\n",
    "    num_workers=2\n",
    ")\n",
    "train_loader = loaders['train']\n",
    "val_loader = loaders['val']\n",
    "test_loader = loaders['test']\n",
    "vocab = loaders['vocabulary']\n",
    "\n",
    "final_model = LSTMMBTIClassifier(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=300,\n",
    "    hidden_dim_1=best_params['hidden_dim_1'],\n",
    "    hidden_dim_2=best_params['hidden_dim_2'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "\n",
    "if best_params['optimizer'] == 'adam':\n",
    "    final_optimizer = torch.optim.Adam(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "elif best_params['optimizer'] == 'adamw':\n",
    "    final_optimizer = torch.optim.AdamW(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "else:\n",
    "    final_optimizer = torch.optim.RMSprop(\n",
    "        final_model.parameters(),\n",
    "        lr=best_params['learning_rate'],\n",
    "        weight_decay=best_params['weight_decay']\n",
    "    )\n",
    "\n",
    "num_params = sum(p.numel() for p in final_model.parameters() if p.requires_grad)\n",
    "print()\n",
    "print(f\"–ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞: {num_params:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\")\n",
    "print(f\"–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä: {best_params['optimizer']}\")\n",
    "print(f\"Learning rate: {best_params['learning_rate']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5501af70"
   },
   "source": [
    "## 14. –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_CMeE5LhO8g"
   },
   "outputs": [],
   "source": [
    "# –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "final_trainer = MBTITrainer(\n",
    "    model=final_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=nn.BCELoss(),\n",
    "    optimizer=final_optimizer,\n",
    "    device=device,\n",
    "    checkpoint_dir='checkpoints/optimized',\n",
    "    save_best_only=True,\n",
    "    early_stopping_patience=5\n",
    ")\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "train_history = {'loss': [], 'acc': []}\n",
    "val_history = {'loss': [], 'acc': []}\n",
    "print(f\"–ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ {NUM_EPOCHS} —ç–ø–æ—Ö...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "BEST_MODEL_PATH = 'best_optimized_model.pth'\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    final_trainer.current_epoch = epoch - 1\n",
    "    train_metrics = final_trainer.train_epoch()\n",
    "    final_trainer.current_epoch = epoch - 1\n",
    "    val_metrics = final_trainer.validate()\n",
    "\n",
    "    train_loss = train_metrics['loss']\n",
    "    train_acc = train_metrics['overall_accuracy']\n",
    "    val_loss = val_metrics['loss']\n",
    "    val_acc = val_metrics['overall_accuracy']\n",
    "\n",
    "    train_history['loss'].append(train_loss)\n",
    "    train_history['acc'].append(train_acc)\n",
    "    val_history['loss'].append(val_loss)\n",
    "    val_history['acc'].append(val_acc)\n",
    "\n",
    "    dichotomy_names = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "    val_dichotomies = {name: val_metrics[f'{name}_accuracy'] for name in dichotomy_names}\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:2d}/{NUM_EPOCHS}: \"\n",
    "        f\"Train Loss={train_loss:.4f}, Acc={train_acc:.4f} | \"\n",
    "        f\"Val Loss={val_loss:.4f}, Acc={val_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        print(\n",
    "            \"  –î–∏—Ö–æ—Ç–æ–º–∏–∏: \" + \", \".join(\n",
    "                [f\"{name}={val_dichotomies[name]:.3f}\" for name in dichotomy_names]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': final_model.state_dict(),\n",
    "            'optimizer_state_dict': final_optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'config': best_params\n",
    "        }, BEST_MODEL_PATH)\n",
    "        print(f\"  ‚úÖ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å! (Val Acc: {val_acc:.4f})\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –õ—É—á—à–∞—è accuracy: {best_val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec898298"
   },
   "source": [
    "## 15. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "–ß—Ä–µ–∑ test_loss, test_acc, test_dichotomies = final_trainer.validate(test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMYqjTabhO8i"
   },
   "outputs": [],
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def evaluate_loader(loader):\n",
    "    final_model.eval()\n",
    "    metrics = MBTIMetrics(device=device)\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            lengths = batch['length'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = final_model(input_ids, lengths)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            batch_size = input_ids.size(0)\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            metrics.update((outputs > 0.5).float(), labels, outputs)\n",
    "\n",
    "    results = metrics.compute()\n",
    "    results['loss'] = total_loss / max(total_samples, 1)\n",
    "    return results\n",
    "\n",
    "test_metrics = evaluate_loader(test_loader)\n",
    "\n",
    "test_loss = test_metrics['loss']\n",
    "test_acc = test_metrics['overall_accuracy']\n",
    "\n",
    "dichotomy_names = ['I/E', 'N/S', 'T/F', 'J/P']\n",
    "test_dichotomies = {name: test_metrics[f'{name}_accuracy'] for name in dichotomy_names}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ù–ê –¢–ï–°–¢–û–í–û–ô –í–´–ë–û–†–ö–ï\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(\"–¢–æ—á–Ω–æ—Å—Ç—å –ø–æ –¥–∏—Ö–æ—Ç–æ–º–∏—è–º:\")\n",
    "for key, value in test_dichotomies.items():\n",
    "    print(f\"  {key}: {value:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(train_history['loss'], label='Train Loss')\n",
    "axes[0].plot(val_history['loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(train_history['acc'], label='Train Acc')\n",
    "axes[1].plot(val_history['acc'], label='Val Acc')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77b54cbd"
   },
   "source": [
    "## 16. –í—ã–≥—Ä—É–∑–∫–∞ –≤ Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3gwTk_yhO8j"
   },
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "import os\n",
    "import shutil\n",
    "save_dir = '/content/drive/MyDrive/MBTI-LSTM-Optimized-Results'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª—ã\n",
    "shutil.copy('best_optimized_model.pth', save_dir)\n",
    "shutil.copy(config_filename, save_dir)\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "results = {\n",
    "    'best_hyperparams': best_params,\n",
    "    'best_val_acc': float(best_val_acc),\n",
    "    'test_acc': float(test_acc),\n",
    "    'test_dichotomies': {k: float(v) for k, v in test_dichotomies.items()},\n",
    "    'num_trials': len(study.trials),\n",
    "    'training_epochs': NUM_EPOCHS,\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "results_filename = f'optimized_results_{datetime.now():%Y%m%d_%H%M}.json'\n",
    "with open(results_filename, 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "shutil.copy(results_filename, save_dir)\n",
    "\n",
    "print(f\"\\\\n‚úÖ –í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Google Drive: {save_dir}\")\n",
    "print(f\"‚úÖ –ú–æ–¥–µ–ª—å: best_optimized_model.pth\")\n",
    "print(f\"‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {config_filename}\")\n",
    "print(f\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {results_filename}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"–ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´\")\n",
    "print(\"=\"*60)\n",
    "print(f\"–õ—É—á—à–∞—è Val Accuracy: {best_val_acc:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"\\\\n–£–ª—É—á—à–µ–Ω–∏–µ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª—å—é:\")\n",
    "print(f\"  –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å: ~71%\")\n",
    "print(f\"  –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è: {test_acc:.1%}\")\n",
    "print(f\"  –ü—Ä–∏—Ä–æ—Å—Ç: +{test_acc*100-71:.1f}%\")\n",
    "\n",
    "if test_acc > 0.75:\n",
    "    print(\"\\\\nüéâ –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ production!\")\n",
    "elif test_acc > 0.72:\n",
    "    print(\"\\\\n‚úÖ –•–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å attention –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è.\")\n",
    "else:\n",
    "    print(\"\\\\n‚ö†Ô∏è –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ:\")\n",
    "    print(\"  - –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –¥–æ 50\")\n",
    "    print(\"  - –î–æ–±–∞–≤–∏—Ç—å attention –º–µ—Ö–∞–Ω–∏–∑–º\")\n",
    "    print(\"  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å pretrained embeddings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9956728"
   },
   "source": [
    "## 17. –ò–ª–∏ —É–¥–∞–ª–∏—Ç—å –∏ –∫–ª–æ–Ω —Å–Ω–æ–≤–∞:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V9X7L0ty9SGp"
   },
   "outputs": [],
   "source": [
    "\n",
    "# –ò–ª–∏ —É–¥–∞–ª–∏—Ç—å –∏ –∫–ª–æ–Ω —Å–Ω–æ–≤–∞:\n",
    "!rm -rf MBTI-LSTM\n",
    "!git clone https://github.com/mueqee/MBTI-LSTM.git\n",
    "%cd MBTI-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fedf6a10"
   },
   "source": [
    "## 18. –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –Ω–∞ 2 —ç–ø–æ—Ö–∏\n",
    "–ß–µ—Ä–µ–∑ !python scripts/train.py \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZwJMcYy9lInx"
   },
   "outputs": [],
   "source": [
    "!python scripts/train.py \\\n",
    "    --data_path data/raw/mbti_dataset.csv \\\n",
    "    --num_epochs 2 \\\n",
    "    --batch_size 32 \\\n",
    "    --checkpoint_dir checkpoints/quick_test\n",
    "\n",
    "print(\"\\n‚úÖ –¢–µ—Å—Ç –ø—Ä–æ–π–¥–µ–Ω! –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKq3F7GdlIny"
   },
   "source": [
    "## 19. –û–±—É—á–µ–Ω–∏–µ –Ω–∞ 50 —ç–ø–æ—Ö\n",
    "\n",
    "–ó–∞–ø—É—Å–∫ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∞ –∏–∑ CLI\n",
    " scripts/train.py, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—É—á–µ–Ω–∏—è –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljertD-alIny"
   },
   "outputs": [],
   "source": [
    "print(\"–ó–∞–ø—É—Å–∫ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –Ω–∞ 50 —ç–ø–æ—Ö...\\n\")\n",
    "\n",
    "!python scripts/train.py \\\n",
    "    --data_path data/raw/mbti_dataset.csv \\\n",
    "    --num_epochs 50 \\\n",
    "    --batch_size 64 \\\n",
    "    --learning_rate 0.001 \\\n",
    "    --optimizer adam \\\n",
    "    --hidden_dim_1 128 \\\n",
    "    --hidden_dim_2 64 \\\n",
    "    --dropout 0.2 \\\n",
    "    --max_length 750 \\\n",
    "    --balance_classes \\\n",
    "    --num_workers 4 \\\n",
    "    --early_stopping_patience 7 \\\n",
    "    --checkpoint_dir checkpoints/final_model\n",
    "\n",
    "print(\"\\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ac030f0"
   },
   "source": [
    "## 20. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "–û–ø–∏—Å–∞–Ω–∏–µ: from google.colab import drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ruR7GV2zlIny"
   },
   "outputs": [],
   "source": [
    "# –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!mkdir -p '/content/drive/MyDrive/MBTI-LSTM-Results'\n",
    "!cp -r checkpoints/final_model '/content/drive/MyDrive/MBTI-LSTM-Results/'\n",
    "!cp -r checkpoints/quick_test '/content/drive/MyDrive/MBTI-LSTM-Results/'\n",
    "\n",
    "print(\"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Google Drive!\")\n",
    "print(\"–ü—É—Ç—å: /content/drive/MyDrive/MBTI-LSTM-Results/\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "state": {},
   "version_major": 2,
   "version_minor": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
